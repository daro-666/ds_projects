import requests
import re
from pathlib import Path
from random import randint
from bs4 import BeautifulSoup
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.naive_bayes import MultinomialNB
from glob import glob
import spacy

nlp = spacy.load("en_core_web_sm")


def make_urllist(artist_url: str) -> list:
    
    '''
    Takes a lyrics.com artistpage url and generates a list of urls to songlyrics.
    '''
    
    urllist = requests.get(artist_url).text
    urllist = re.findall("/lyric/.*?\"", urllist)
    for i in range(len(urllist)):
        urllist[i] = re.sub("\"", "", urllist[i])
        urllist[i] = "https://www.lyrics.com"+urllist[i]
    
    return urllist


def get_pathlist(urllist: list) -> list:

    '''
    Takes a urllist generated by make_urllist and creates a filepathlist containing paths of the form: "../data/Artists/artistname/songname.txt"
    '''

    path_list = []
    artist = re.sub("\+", "_", re.findall("(?<=\d/).*(?=/)",urllist[0])[0])
    regex = artist[-3:]+"/"

    Path("../data/Artists/"+artist).mkdir(parents=True, exist_ok=True)

    for url in urllist:
        path = re.sub("\+", "_", re.findall("(?<="+regex+").*", url)[0])
        path = re.sub("(%..)|(_%..)","",path)
        path = path.lower()
        path = path+".txt"
        path = "../data/Artists/"+artist+"/"+path
        path_list.append(path)

    return path_list


def dwnld_sng_txt(artisturl: list, num=1, verb=True) -> None:

    '''
    Takes an url to a lyrics.com artist-page and downloads a specified number of randomly chosen lyrics.
    '''

    urllist = make_urllist(artisturl)
    path_list = get_pathlist(urllist)
    counter = 0
    dup = 0
    frq = 0
    nolyrics = 0

    while counter < num:
        i = randint(0, len(urllist)-1)

        path = path_list[i]

        if Path(path).is_file() == False:
            song_rqst = requests.get(urllist[i])
            if song_rqst.status_code == 200:
                
                if bool(re.search("lyric-no-data",song_rqst.text)) == True:
                    nolyrics += 1
                else:
                    with open(path, "w") as file:
                        file.write(BeautifulSoup(song_rqst.text, features="html.parser").find_all(class_="lyric-body")[0].text)
                    counter += 1
            else:
                frq += 1
        else:
            dup += 1
    
    if verb == True:
        print(f"Success           = {counter}")
        print(f"Failed request    = {frq}")
        print(f"Duplicate         = {dup}")
        print(f"No lyrics on page = {nolyrics}")


def cleanstr(lyrics: str) -> str:

    '''
    Converts str contents into lowercase words without punctuation separated by a single whitespace
    '''

    lyrics = re.sub("\\n|\,|\(|\)|\?|\!|\.|-|_", " ", lyrics)
    lyrics = re.sub("ain't", "", lyrics)
    lyrics = re.sub("\'s", " is", lyrics)
    lyrics = re.sub("\'t", " not", lyrics)
    lyrics = re.sub("\'ve", " have", lyrics)
    lyrics = re.sub("\'ll", " will", lyrics)
    lyrics = re.sub("\'em", "them", lyrics)
    lyrics = re.sub("\'re", " are", lyrics)
    lyrics = re.sub("\'m", " am", lyrics)
    lyrics = re.sub("\s{2,}", " ", lyrics)
    lyrics = re.sub("^\s|\s$", "", lyrics)
    lyrics = lyrics.lower()
    
    return lyrics


def gen_corpus_labels(list_of_paths_to_txt: list) -> list:

    '''
    Generates a list of 2 lists of the form: [listofsongtexts, listofartists].
    '''

    corpus = []
    labels = []

    for path in list_of_paths_to_txt:
    
        artist = re.findall("(?<=Artists/).*(?=/)",path)[0]
        labels.append(artist)

        with open(path, "r") as file:
            lyrics = file.read()
        corpus.append(cleanstr(lyrics))

    return [corpus, labels]


def artist_predictor(lyrics: str) -> list:
    
    """
    This is the main function for artist_checker.py
    """

    filepathlist = glob("/home/david/spiced_projects/poisson-ivy-student-code/week4/data/Artists/*/*.txt")

    cor_lab_list = gen_corpus_labels(filepathlist)

    vctrzr = TfidfVectorizer(token_pattern=None, tokenizer=lemmatizer, ngram_range=(1, 2))#, max_df=0.75)

    X = vctrzr.fit_transform(cor_lab_list[0]).toarray()
    y = cor_lab_list[1].copy()

    nb = MultinomialNB().fit(X,y)

    new_song = lyrics
    new_song_clean = cleanstr(new_song)
    new_song_cl_lm = lemmatizer(new_song_clean)
    new_song = [new_song_clean]

    new_song_vctrzd = vctrzr.transform(new_song)

    art_pred_list = [nb.predict(new_song_vctrzd)[0], round(max(nb.predict_proba(new_song_vctrzd)[0])*100, 1), new_song_cl_lm]

    return art_pred_list


def lemmatizer(text: str) -> list:
    
    """
    Use spacy to convert words to lemmas
    """

    doc = nlp(text)
    lemmas = [token.lemma_ for token in doc if not token.is_stop]

    return lemmas


def link_to_lyrics(link: str) -> str:

    """
    Takes a lyrics link and extracts songlyrics
    """
   
    song_rqst = requests.get(link)
    
    if song_rqst.status_code == 200:
        if bool(re.search("lyric-no-data",song_rqst.text)) == False:
            return BeautifulSoup(song_rqst.text, features="html.parser").find_all(class_="lyric-body")[0].text
        else:
            return "No lyrics"
    else:
        return "Request failed"
               